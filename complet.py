import os
import sys
import threading
import time
import re
import requests
from PyPDF2 import PdfReader
from fpdf import FPDF
from langchain_ollama import OllamaLLM
from langchain.prompts import PromptTemplate
import itertools
import json
from datetime import datetime
import unicodedata
from typing import Dict, List, Optional

# === Configuration ===
INPUT_PDF_PATH = os.path.join("pdfs", "document.pdf")
OUTPUT_PDF_PATH = os.path.join("output", "rapport_porter_enrichi.pdf")
MODEL_NAME = "llama3:instruct"
SPINNER_RUNNING = True

# Optionnel : API keys pour des recherches plus avanc√©es
SERPAPI_KEY = os.getenv("SERPAPI_KEY")  # Pour Google Search API
NEWSAPI_KEY = os.getenv("NEWSAPI_KEY")  # Pour News API


# === Animation spinner ===
def spinner(message="üîÑ Traitement en cours..."):
    for c in itertools.cycle(["|", "/", "-", "\\"]):
        if not SPINNER_RUNNING:
            break
        sys.stdout.write(f"\r{message} {c}")
        sys.stdout.flush()
        time.sleep(0.1)
    sys.stdout.write(f"\r‚úÖ {message.replace('üîÑ', '').strip()} termin√© !       \n")


# === √âtape 1 : Lire le contenu du PDF ===
def read_pdf(file_path: str) -> str:
    reader = PdfReader(file_path)
    text = ""
    for page in reader.pages:
        text += page.extract_text() or ""
    return text.strip()


# === √âtape 2 : Extraire les informations de l'entreprise ===
def extract_company_info(text: str) -> Dict[str, any]:
    """Extrait le nom de l'entreprise et ses domaines d'activit√© du PDF"""

    template = """
    Analyse le texte suivant et extrait uniquement les informations demand√©es au format JSON :

    {text}

    Retourne UNIQUEMENT un JSON valide avec cette structure exacte :
    {{
        "nom_entreprise": "nom exact de l'entreprise",
        "domaines_activite": ["domaine1", "domaine2", "domaine3"],
        "secteur_principal": "secteur principal",
        "pays": "pays o√π op√®re l'entreprise",
        "concurrents_mentionnes": ["concurrent1", "concurrent2"]
    }}

    Assure-toi que le JSON soit valide et sans texte suppl√©mentaire.
    """

    prompt = PromptTemplate(template=template, input_variables=["text"])
    llm = OllamaLLM(model=MODEL_NAME)
    runner = prompt | llm

    global SPINNER_RUNNING
    SPINNER_RUNNING = True
    t = threading.Thread(target=spinner, args=("üîç Extraction des informations entreprise...",))
    t.start()

    try:
        result = runner.invoke({"text": text[:8000]})
        SPINNER_RUNNING = False
        t.join()

        # Nettoyer le r√©sultat et extraire le JSON
        json_match = re.search(r'\{.*\}', result, re.DOTALL)
        if json_match:
            company_info = json.loads(json_match.group())
            print(company_info)
            return company_info
        else:
            print("‚ö†Ô∏è  Impossible d'extraire les informations au format JSON")
            return {}
    except Exception as e:
        SPINNER_RUNNING = False
        t.join()
        print(f"‚ùå Erreur lors de l'extraction : {e}")
        return {}


# === √âtape 3 : Recherche web enrichie ===
def web_search_basic(query: str, num_results: int = 5) -> List[Dict]:
    """Recherche web basique avec requests (sans API payante)"""
    try:
        # Simulation d'une recherche - √† remplacer par une vraie API
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }

        # Pour une vraie impl√©mentation, utilisez une API comme SerpAPI, Google Custom Search, etc.
        # Simulation avec dates et sources r√©alistes pour le template
        current_date = datetime.now()
        results = [
            {
                "title": f"Derni√®res actualit√©s - {query}",
                "snippet": "Informations r√©centes trouv√©es sur le web avec contexte d√©taill√©...",
                "url": "https://example.com/news/article1",
                "date": current_date.strftime("%Y-%m-%d"),
                "source": "Les √âchos",
                "published_date": "2025-01-15"
            },
            {
                "title": f"Analyse sectorielle - {query}",
                "snippet": "√âtude approfondie des tendances du march√©...",
                "url": "https://example.com/analysis/sector",
                "date": current_date.strftime("%Y-%m-%d"),
                "source": "Reuters",
                "published_date": "2025-01-10"
            }
        ]

        return results[:num_results]
    except Exception as e:
        print(f"‚ùå Erreur de recherche web : {e}")
        return []


def collect_company_data(company_info: Dict) -> Dict[str, List]:
    """Collecte des donn√©es web sur l'entreprise et ses concurrents"""

    if not company_info.get("nom_entreprise"):
        return {"error": "Nom d'entreprise non trouv√©"}

    company_name = company_info["nom_entreprise"]
    domains = company_info.get("domaines_activite", [])
    competitors = company_info.get("concurrents_mentionnes", [])

    collected_data = {
        "company_official": [],
        "company_linkedin": [],
        "industry_news": [],
        "competitor_news": [],
        "search_metadata": {
            "timestamp": datetime.now().isoformat(),
            "company": company_name,
            "domains_searched": domains,
            "competitors_searched": competitors
        }
    }

    global SPINNER_RUNNING

    # 1. Site officiel de l'entreprise
    SPINNER_RUNNING = True
    t1 = threading.Thread(target=spinner, args=("üåê Recherche site officiel...",))
    t1.start()

    official_query = f"{company_name} site officiel actualit√©s 2025"
    collected_data["company_official"] = web_search_basic(official_query, 5)
    print(collected_data["company_official"])
    SPINNER_RUNNING = False
    t1.join()

    # 2. LinkedIn de l'entreprise
    SPINNER_RUNNING = True
    t2 = threading.Thread(target=spinner, args=("üíº Recherche LinkedIn entreprise...",))
    t2.start()

    linkedin_query = f"{company_name} linkedin company news updates"
    collected_data["company_linkedin"] = web_search_basic(linkedin_query, 5)
    print(collected_data["company_linkedin"])
    SPINNER_RUNNING = False
    t2.join()

    # 3. Actualit√©s du secteur pour chaque domaine
    for domain in domains[:3]:  # Limiter √† 3 domaines
        SPINNER_RUNNING = True
        t3 = threading.Thread(target=spinner, args=(f"üì∞ Actualit√©s {domain}...",))
        t3.start()

        news_query = f"actualit√©s {domain} tendances march√© janvier 2025"
        domain_news = web_search_basic(news_query, 4)

        # Ajouter m√©tadonn√©es pour identifier le domaine
        for news in domain_news:
            news["domain"] = domain
            news["search_type"] = "industry_news"

        collected_data["industry_news"].extend(domain_news)
        print(collected_data["industry_news"])
        SPINNER_RUNNING = False
        t3.join()

    # 4. Actualit√©s des concurrents
    for competitor in competitors[:4]:  # Limiter √† 4 concurrents
        SPINNER_RUNNING = True
        t4 = threading.Thread(target=spinner, args=(f"üè¢ Actualit√©s {competitor}...",))
        t4.start()

        competitor_query = f'"{competitor}" actualit√©s news 2025 strat√©gie'
        competitor_news = web_search_basic(competitor_query, 10)

        # Ajouter m√©tadonn√©es pour identifier le concurrent
        for news in competitor_news:
            news["competitor"] = competitor
            news["search_type"] = "competitor_news"

        collected_data["competitor_news"].extend(competitor_news)

        SPINNER_RUNNING = False
        t4.join()

    return collected_data


# === √âtape 4 : G√©n√©rer l'analyse Porter enrichie ===
def generate_enhanced_porter_analysis(original_text: str, company_info: Dict, web_data: Dict) -> str:
    """G√©n√®re une analyse Porter enrichie avec les donn√©es web"""

    template = """
    Tu es un expert en strat√©gie d'entreprise et en intelligence √©conomique.

    Ta mission est de cr√©er un **rapport en francais enrichi d'au moins 10 000 caract√®res** selon le mod√®le des **5 forces de Porter**, pour l‚Äôentreprise suivante, en exploitant toutes les donn√©es fournies :

    ---

    ## INFORMATIONS ENTREPRISE :
    {company_info}

    ## DOCUMENT ORIGINAL :
    {original_text}

    ## DONN√âES WEB COLLECT√âES :
    {web_data}

    ---

    G√©n√®re un rapport selon cette structure **exacte** :

    # RAPPORT D'ANALYSE PORTER ENRICHI - {company_name}

    ## SYNTH√àSE EX√âCUTIVE  
    Fais une synth√®se dense, percutante et strat√©gique des forces en pr√©sence et de la position concurrentielle globale de l'entreprise.

    ## INFORMATIONS ENTREPRISE
    - **Nom** : {company_name}  
    - **Secteurs d'activit√©** : {domains}  
    - **Positionnement** : analyse bas√©e sur les donn√©es disponibles et les actualit√©s collect√©es

    ---

    ## 1. RIVALIT√â ENTRE CONCURRENTS EXISTANTS  
    ### Donn√©es du march√© r√©centes  
    [Inclure au minimum une actualit√© r√©cente sur un concurrent direct avec date et source]  

    ### Analyse strat√©gique  
    - Nombre et taille des concurrents  
    - Intensit√© concurrentielle actuelle  
    - Innovations ou diff√©renciations identifi√©es  
    - Parts de march√© estim√©es  
    - Barri√®res de sortie

    ---

    ## 2. MENACE DES NOUVEAUX ENTRANTS  
    ### Tendances du secteur  
    [Inclure au minimum une actualit√© sur les nouvelles entreprises ou innovations entrantes]  

    ### Analyse  
    - Barri√®res √† l'entr√©e actuelles  
    - √âvolution r√©glementaire r√©cente  
    - Besoins en capital / technologie  
    - Nouveaux entrants identifi√©s

    ---

    ## 3. MENACE DES PRODUITS DE SUBSTITUTION  
    ### Innovations / Disruptions identifi√©es  
    [Utiliser les donn√©es web pour citer au moins une technologie ou alternative cr√©dible]  

    ### Analyse  
    - Substituts viables et en d√©veloppement  
    - Facilit√© de substitution pour les clients  
    - Niveau de menace pour le mod√®le √©conomique actuel

    ---

    ## 4. POUVOIR DE N√âGOCIATION DES CLIENTS  
    ### √âvolution du march√© client  
    [Bas√© sur les tendances web avec source]  

    ### Analyse  
    - Volume et diversit√© de la client√®le  
    - Sensibilit√© prix et comportement d‚Äôachat  
    - Possibilit√©s de substitution c√¥t√© client  
    - Tendances comportementales r√©centes

    ---

    ## 5. POUVOIR DE N√âGOCIATION DES FOURNISSEURS  
    ### Informations sur la cha√Æne d‚Äôapprovisionnement  
    [Bas√© sur les donn√©es ou actualit√©s r√©centes si pr√©sentes]  

    ### Analyse  
    - Concentration des fournisseurs  
    - Sp√©cificit√© des intrants  
    - Risques d‚Äôapprovisionnement  
    - N√©gociation et d√©pendance

    ---

    ## DERNI√àRES ACTUALIT√âS SECTORIELLES  
    **Inclure obligatoirement au moins 3 actualit√©s pertinentes** pour **les domaines d‚Äôactivit√© de l‚Äôentreprise**, et **au moins 3 pour ses concurrents directs**.

    ### Actualit√©s des domaines d'activit√©  
    Pour chaque actualit√© :  
    - **Titre**  
    - **Date de publication**  
    - **Source** (nom du m√©dia/site)  
    - **R√©sum√©** : au moins 500 caract√®res  
    - **Impact strat√©gique** : en quoi cela affecte l‚Äôentreprise

    ### Actualit√©s des concurrents identifi√©s  
    Pour chaque actualit√© li√©e √† un concurrent :  
    - **Concurrent concern√©**  
    - **Titre de l‚Äôactualit√©**  
    - **Date de publication**  
    - **Source**  
    - **R√©sum√©** : au moins 500 caract√®res  
    - **Analyse strat√©gique** : implication concurrentielle, menace ou opportunit√©

    ---

    ## RECOMMANDATIONS STRAT√âGIQUES ENRICHIES  
    ### Actions prioritaires  
    1. **Court terme (0-6 mois)** : d√©cisions op√©rationnelles rapides bas√©es sur les derni√®res actualit√©s  
    2. **Moyen terme (6-18 mois)** : alignement strat√©gique bas√© sur les tendances sectorielles  
    3. **Long terme (18+ mois)** : anticipation et vision strat√©gique durable

    ### Opportunit√©s identifi√©es  
    [Bas√© sur les actualit√©s et donn√©es avec sources]

    ### Menaces √† surveiller  
    [Bas√© sur l‚Äôanalyse concurrentielle ou environnementale]

    ---

    ## SOURCES ET VEILLE STRAT√âGIQUE  
    - Liste des **sources officielles** (avec URL)  
    - Liste des **actualit√©s sectorielles analys√©es** (titre, date, source, lien si disponible)  
    - Liste des **sources concurrentielles** utilis√©es  
    - Recommandations de veille continue (indicateurs, fr√©quence, outils)

    ---

    **IMPORTANT :**
    - Fournir **au moins 10 000 caract√®res** (ne r√©sume pas trop).  
    - Pour chaque actualit√©, inclure la **date de publication**, le **nom de la source**, et **le lien** (si disponible).  
    - R√©ponds uniquement avec le rapport structur√© ci-dessus. Aucun texte hors-structure. Pas d'introduction ni de conclusion globale hors rapport.
    """

    company_name = company_info.get("nom_entreprise", "Entreprise")
    domains = ", ".join(company_info.get("domaines_activite", []))

    prompt = PromptTemplate(
        template=template,
        input_variables=["company_info", "original_text", "web_data", "company_name", "domains"]
    )

    llm = OllamaLLM(model=MODEL_NAME)
    runner = prompt | llm

    global SPINNER_RUNNING
    SPINNER_RUNNING = True
    t = threading.Thread(target=spinner, args=("üß† G√©n√©ration analyse Porter enrichie...",))
    t.start()

    result = runner.invoke({
        "company_info": json.dumps(company_info, indent=2, ensure_ascii=False),
        "original_text": original_text[:4000],
        "web_data": json.dumps(web_data, indent=2, ensure_ascii=False)[:3000],
        "company_name": company_name,
        "domains": domains
    })

    SPINNER_RUNNING = False
    t.join()

    return result


# === √âtape 5 : G√©n√©rer un PDF enrichi ===
def clean_text(text: str) -> str:
    """Nettoie les caract√®res sp√©ciaux pour √©viter les erreurs Unicode dans le PDF."""
    return unicodedata.normalize("NFKD", text).encode("ASCII", "ignore").decode("ASCII")


def create_enhanced_pdf_report(text: str, company_info: Dict, output_path: str):
    """Cr√©e un PDF enrichi avec m√©tadonn√©es"""

    pdf = FPDF()
    pdf.add_page()

    # En-t√™te
    pdf.set_font("Arial", "B", 16)
    company_name = company_info.get("nom_entreprise", "Entreprise")
    pdf.cell(0, 10, f"ANALYSE PORTER - {clean_text(company_name)}", ln=True, align="C")

    pdf.set_font("Arial", size=10)
    pdf.cell(0, 5, f"Genere le {datetime.now().strftime('%d/%m/%Y %H:%M')}", ln=True, align="C")
    pdf.ln(10)

    # Contenu
    pdf.set_font("Arial", size=10)
    lines = text.split("\n")

    for line in lines:
        cleaned_line = clean_text(line)
        if line.startswith("#"):
            pdf.set_font("Arial", "B", 12)
        elif line.startswith("##"):
            pdf.set_font("Arial", "B", 11)
        else:
            pdf.set_font("Arial", size=10)

        pdf.multi_cell(0, 6, cleaned_line)
        pdf.ln(2)

    # Cr√©er le dossier output s'il n'existe pas
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    pdf.output(output_path)


# === Main enrichi ===
